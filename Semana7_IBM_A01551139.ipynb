{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PosgradoMNA/actividades-de-aprendizaje-AdrianaCamarillo-A01551139/blob/main/Semana7_IBM_A01551139.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Actividad de semana 7: Data Analysis with Python (IBM)\n",
        "\n",
        "## Materia: Ciencia y analítica de datos\n",
        "\n",
        "Prof María de la Paz Rico\n",
        "\n",
        "Prof Roberto Antonio Guevara González\n",
        "\n",
        "## Nombre: Adriana Camarillo Duran\n",
        "\n",
        "## Matrícula: A01551139\n",
        "\n",
        "Fecha de entrega: 01/11/2022\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_PU3bIN8TIrq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Module 4 - Model Development"
      ],
      "metadata": {
        "id": "MyWXE-oUTKtu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un modelo o estimador puede ser visto como una ecuación matemática usada para predecir un valor dado uno o más valores. Esto se hace a través de la relación de una o más variables independientes a variables dependientes.\n",
        "\n",
        "Entre más relevantes sean los datos que tenemos, mejor serán las predicciones."
      ],
      "metadata": {
        "id": "xG4RkkC2E5_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regresión Lineal y Regresión Lineal Múltiple"
      ],
      "metadata": {
        "id": "J4_rvM-5E6XK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Regresión lineal se va a referir a una variable independiente para hacer una predicción\n",
        "- Regresión lineal múltiple se va a referir a múltiples variables independientes para hacer una predicción"
      ],
      "metadata": {
        "id": "NOn-5Pjngyn0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regresión lineal simple\n",
        "1. Variable predictora (independiente) - x\n",
        "2. Variable objetivo (dependiente) - y\n",
        "$$y = b_0 + b_1x$$\n",
        "Donde $b_0$ es el intercepto y $b_1$ es la pendiente"
      ],
      "metadata": {
        "id": "KVn1PZosGJeW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para entrenar un modelo de regresión lineal simple en python, necesitamos importar linear_model de scikit-learn:"
      ],
      "metadata": {
        "id": "NwwOHsCsGrNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "h33GOvhAGImT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego debemos crear un objeto de Regresión Lineal usando un constructor:"
      ],
      "metadata": {
        "id": "r3M98b7xsmoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm= LinearRegression()"
      ],
      "metadata": {
        "id": "Ts758XJUE8a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego debemos definir las variables predictora y objetivo, así como usar el método .fit() para entrenar el modelo, o sea encontrar los parámetros $b_0$ y $b_1$"
      ],
      "metadata": {
        "id": "NJKNuqx6suTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X= df['variable_predictora']\n",
        "Y= df['variable_objetivo']\n",
        "\n",
        "lm.fit(X,Y)"
      ],
      "metadata": {
        "id": "7yLl25_-sudh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y finalmente podemos obtener una predicción con .predict():"
      ],
      "metadata": {
        "id": "KI-aU9h5tLgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Yhat= lm.predict(X)"
      ],
      "metadata": {
        "id": "Y95VnQIZtK27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si quisieramos ver los parámetros obtenidos en el entrenamiento del modelo, lo podemos hacer con los siguientes atributos de lm:\n",
        "- .intercept_ para $b_0$\n",
        "- .coef_ para $b_1$"
      ],
      "metadata": {
        "id": "MADQu1O1tXKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm.intercept_\n",
        "lm.coef_"
      ],
      "metadata": {
        "id": "NGPtThm0tXSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regresión lineal múltiple\n",
        "1. Variables predictoras (independiente) - $x_1$, $x_2$, ..., $x_n$\n",
        "2. Variable objetivo (dependiente) - $y$\n",
        "$$y = b_0 + b_1x + b_2x_2 + ... + b_nx_n$$\n",
        "Donde $b_0$ es el intercepto y $b_i$ es el coeficiete del parámetro $x_i$ para $i= 1,2,...,n$"
      ],
      "metadata": {
        "id": "aFIBF1BovEm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La manera de entrenar un modelo en python sería muy similar a la regresión lineal simple:"
      ],
      "metadata": {
        "id": "ep10rl6-v_3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Z= df[['variable_predictora1','variable_predictora2','variable_predictora3']]\n",
        "lm.fit(Z, df['variable_objetivo'])\n",
        "Yhat=lm.predict(X)"
      ],
      "metadata": {
        "id": "IUFRApfrwAPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si quisieramos ver los parámetros obtenidos en el entrenamiento del modelo, se utilizarían los mismos atributos:\n",
        "- .intercept_ para $b_0$\n",
        "- .coef_ para $b_1, b_2, ..., b_n$"
      ],
      "metadata": {
        "id": "vu5y5DZtwfp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm.intercept_\n",
        "lm.coef_"
      ],
      "metadata": {
        "id": "TBAWkk7ewoEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluación del Modelo con Visualización"
      ],
      "metadata": {
        "id": "q2-VM0spE82l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los gráficos de regresión son útiles para darnos un buen estimado de:\n",
        "1. La relación entre dos variables\n",
        "2. La fuerza de la correlación\n",
        "3. La dirección de la relación (positiva o negativa)\n",
        "\n",
        "El eje horizontal suele ser la variable independiente y la vertical es la dependiente.\n",
        "\n"
      ],
      "metadata": {
        "id": "CuaxAoKBKZPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con seaborn podemos crear estas gráficas:"
      ],
      "metadata": {
        "id": "-NcOu1RZxKOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.regplot(x='variable_independiente', y='variable_objetivo', data=df)\n",
        "plt.ylim(0,)"
      ],
      "metadata": {
        "id": "3ZHEeYVaxJfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con un plot residual podemos representar el error entre los valores reales. En este caso, los errores se ven en el eje vertical y la variable dependiente en el horizontal.\n",
        "\n",
        "Se esperaría que los errores tuvieran un promedio de 0 y con una varianza constante.\n",
        "\n",
        "Si la gráfica no se comportara como se mencionó anteriormente, y por ejemplo siguiera una curva, entonces tal vez un modelo no-lineal sería más apropiado."
      ],
      "metadata": {
        "id": "8DFtrEYpXvLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con seaborn también podemos hacer el plot residual"
      ],
      "metadata": {
        "id": "VvKNzL2Fyp87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.residplot(df['variable_independiente','variable_objetivo'])"
      ],
      "metadata": {
        "id": "mkB6N8f9ypbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los plot de distribución son útiles para visualizar modelos con más de una variable independiente y comparar los valores reales vs las predicciones."
      ],
      "metadata": {
        "id": "dRv4bpuiy1Z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "ax1= sns.distplot(df['variable_objetivo', hist=False, color='r', label='Actual Value'])\n",
        "sns.distplot(Yhat, hist=False, color='b', label='Fitted Values', ax=ax1)"
      ],
      "metadata": {
        "id": "7vrcFCGAYIOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regresión Polinomial y Pipelines"
      ],
      "metadata": {
        "id": "UC4gmW8DFiuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regresión Polonomial\n",
        "Es un caso especial de un modelo de regresión lineal general que es útil para describir relaciones curvilíneas, a través de términos cuadráticos o de más alto orden de las variables predictoras.\n",
        "\n",
        "El modelo puede ser: \n",
        "- Cuadrático - 2do orden\n",
        "$$\\hat{Y} = b_0 + b_1x_1 + b_2(x_1)^2$$\n",
        "- Cúbico - 3er orden\n",
        "$$\\hat{Y} = b_0 + b_1x_1 + b_2(x_1)^2 + b_2(x_1)^3$$\n",
        "- Orden aún mayor\n",
        "$$\\hat{Y} = b_0 + b_1x_1 + b_2(x_1)^2 + b_2(x_1)^3 + ...$$"
      ],
      "metadata": {
        "id": "xGlzbHlzFkYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En python, se pueden crear modelos de regresión polinomial con el método polyfit() de numpy. Para crear un modelo de 3er orden se haría así:"
      ],
      "metadata": {
        "id": "T2t5KEtS2_DF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f= np.polyfit(x,y,3)\n",
        "p= np.polyd(f)"
      ],
      "metadata": {
        "id": "HCJFTKmzFjjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y podemos ver el modelo imprimiendo p:"
      ],
      "metadata": {
        "id": "1EqOeZ3F3Xc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(p)"
      ],
      "metadata": {
        "id": "FePeB_OZsSt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para crear un objeto de variable polinomial, usamos la librería de sci-kit-learn \"preprocessing\""
      ],
      "metadata": {
        "id": "ApXAoMv63a3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "pr=PolynomialFeatures(degree=2, include_bins=False)\n",
        "\n",
        "x_polly= pr.fit_transform(x[['variable1', 'variable2']])"
      ],
      "metadata": {
        "id": "4OTBD_3c3blr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando tenemos un tamaño muy grande de datos, es conveniente hacer varios pasos a la vez. Como por ejemplo normalizar las variables de manera simultánea:"
      ],
      "metadata": {
        "id": "f7Kj2mMpHGrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "SCALE= StandardScaler()\n",
        "SCALE.fit(x_data[['variable1','variable2']])\n",
        "\n",
        "x_scale= SCALE.transdorm(x_data[['variable1','variable2']])"
      ],
      "metadata": {
        "id": "Wo9DZtJ64Deq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los pipelines son muy útiles para realizar varios pasos para obtener una predicción. En este caso tenemos estos pasos:\n",
        "1. Normalización\n",
        "2. Transformación polinomial\n",
        "3. Regresión Lineal (predicción)"
      ],
      "metadata": {
        "id": "r4GCc4V9Hv44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Este es un ejemplo de un constructor Pipeline:"
      ],
      "metadata": {
        "id": "DVgtlk1LIGxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input= [('scale', StandarScaler()), ('polynomial', PolynomialFeatures(degree=2)), ('model', LinearRegression())]\n",
        "pipe= Pipeline(input)"
      ],
      "metadata": {
        "id": "PnvtrfSjHwTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos entrenar el objeto pipeline, el cual ya incluirá todos los pasos y transformaciones necesarias:"
      ],
      "metadata": {
        "id": "V60UqcSuIlIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.train(X[['variable1', 'variable2', 'variable3','variable4']], y)\n",
        "yhat= pipe.predict(X[['variable1', 'variable2', 'variable3','variable4']])"
      ],
      "metadata": {
        "id": "ACY0ZDorInLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Medidas para Evaluación In-Sample"
      ],
      "metadata": {
        "id": "fUa0TdWxFohq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para determinar que tan bien encaja un modelo en un dataset, existen dos métricas importantes:\n",
        "- Mean Squared Error (MSE): \n",
        "- R-squared ($R^2$)"
      ],
      "metadata": {
        "id": "pQEX7hcCFopH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para medir el MSE en python podemos hacer lo siguiente: "
      ],
      "metadata": {
        "id": "xE85b7xZJ-xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(df['variable_objetivo'], Y_predict_simple_fit)"
      ],
      "metadata": {
        "id": "C32HOxzXJ9LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El coeficiente de determinación o $R^2$ es una métrica que determina que tan cerca están los datos de la línea de regresión ajustada. Es el percentaje de variación de la variable objetivo (Y) que está explicada por el modelo lineal."
      ],
      "metadata": {
        "id": "7AVlxL3sTAOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En python, podemos calcular el coeficiente de la siguiente manera:"
      ],
      "metadata": {
        "id": "VL5vfCrxKj7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X= df['variable_independiente']\n",
        "Y= df['variable_objetivo']\n",
        "\n",
        "lm.fit(X,Y)\n",
        "\n",
        "lm.score(X,y)"
      ],
      "metadata": {
        "id": "w5uEz3XtFlM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicción y toma de decisiones"
      ],
      "metadata": {
        "id": "QdqzRI6bTkTD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para tomar decisiones y encontrar el modelo final con el mejor ajuste es importante tomar en cuenta lo siguiente:\n",
        "- Revisar si hacen sentido las predicciones\n",
        "- Visualización\n",
        "- Medidas numéricas para evaluación\n",
        "- Comparar modelos\n"
      ],
      "metadata": {
        "id": "COj4vaI4T5_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para generar una secuencia de valores, podemos usar la función arrange de numpy:"
      ],
      "metadata": {
        "id": "sPuWJ3jUNnkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "new_input= np.arrange(1, 101, 1).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "Pz8dOdXzT8er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un MSE menor, no siempre implica un mejor fit del modelo. Generalmente el MSE de un Regresión Lineal Múltiple va a ser más chico que el de un modelo de Regresión Lineal Simple. También el SME de un modelo de regresión polinomial suele ser menor que el de regresión regular. Lo mismo suele suceder para el $R^2$"
      ],
      "metadata": {
        "id": "p9MWN8qkXTys"
      }
    }
  ]
}